{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a661620",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c720025",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install CounterVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bec5cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f148b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3172dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as nd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd108353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.util import pr\n",
    "stemmer=nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e4c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "826e6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.util import pr\n",
    "stemmer=nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7128d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "df=nd.read_csv(\"twitter_data.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c492de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "\n",
      "                        labels  \n",
      "0                          NaN  \n",
      "1  Offensive language detected  \n",
      "2  Offensive language detected  \n",
      "3  Offensive language detected  \n",
      "4  Offensive language detected  \n"
     ]
    }
   ],
   "source": [
    "df[\"labels\"]=df['class'].map({0:\"Hate Speech Detected\",1:\"Offensive language detected\",3:\"No hate and Offensive speech\"})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b35a741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>Offensive language detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>Offensive language detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>Offensive language detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>Offensive language detected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                        labels  \n",
       "0                          NaN  \n",
       "1  Offensive language detected  \n",
       "2  Offensive language detected  \n",
       "3  Offensive language detected  \n",
       "4  Offensive language detected  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['tweet','labels']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "554322f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0   rt mayasolov woman shouldnt complain clean ho...   \n",
      "1   rt  boy dat coldtyga dwn bad cuffin dat hoe  ...   \n",
      "2   rt urkindofbrand dawg rt  ever fuck bitch sta...   \n",
      "3             rt cganderson vivabas look like tranni   \n",
      "4   rt shenikarobert shit hear might true might f...   \n",
      "\n",
      "                        labels  \n",
      "0                          NaN  \n",
      "1  Offensive language detected  \n",
      "2  Offensive language detected  \n",
      "3  Offensive language detected  \n",
      "4  Offensive language detected  \n"
     ]
    }
   ],
   "source": [
    "def clean(text):\n",
    "    text=str(text).lower()\n",
    "    text=re.sub('\\[.*?\\]','',text)\n",
    "    text=re.sub('https?://\\S+|www\\.\\S+','',text)\n",
    "    text=re.sub('<.*?>+','',text)\n",
    "    text=re.sub('[%s]' % re.escape(string.punctuation),'',text)\n",
    "    text=re.sub('\\n','',text)\n",
    "    text=re.sub('\\w*\\d\\w*','',text)\n",
    "    text=[word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    text=[stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text\n",
    "df['tweet'] = df['tweet'].apply(clean)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17fc9978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array(df[\"tweet\"])\n",
    "y=np.array(df[\"labels\"])\n",
    "cv=CountVectorizer()\n",
    "x=cv.fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "y_train = y_train.astype(str)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4f0c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hate Speech Detected']\n"
     ]
    }
   ],
   "source": [
    "test_data=\"i will kill you\"\n",
    "df=cv.transform([test_data]).toarray()\n",
    "print(clf.predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a09fdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\n",
      "ERROR: No matching distribution found for pickle\n"
     ]
    }
   ],
   "source": [
    " pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a40dd104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename='savemodel.sav'\n",
    "pickle.dump(clf,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95a11af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hate Speech Detected']\n"
     ]
    }
   ],
   "source": [
    "load_model=pickle.load(open(filename,'rb'))\n",
    "test_data=\"i will kill you\"\n",
    "df=cv.transform([test_data]).toarray()\n",
    "\n",
    "print(load_model.predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a447b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
